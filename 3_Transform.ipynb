{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abd1278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "from io import StringIO\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66548aa",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9cfddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 61.10it/s]\n"
     ]
    }
   ],
   "source": [
    "## Code to extract all metadata; by GPT 4 --> metadata_complete.pkl\n",
    "\n",
    "md_final = {}\n",
    "\n",
    "with open('course_pages.jsonl', 'r') as f:\n",
    "   for line in tqdm(f):\n",
    "       j = json.loads(line)\n",
    "       md_final[j['url']] = {}\n",
    "       soup = BeautifulSoup(j['text'], 'html.parser')\n",
    "       h2 = soup.select_one(\"div.metadata > h2\")\n",
    "       if h2:\n",
    "           md_final[j['url']]['title'] = h2.get_text(strip=True)\n",
    "       for dt in soup.select(\"div.metadata dt\"):\n",
    "           dd = dt.find_next_sibling(\"dd\")\n",
    "           if dd:\n",
    "               key = dt.get_text(strip=True)\n",
    "               val = dd.get_text(strip=True)\n",
    "               md_final[j['url']][key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "824bb9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Yields term; searches in the entry of metadata for matches; Gen by GPT4 --> time.pkl\n",
    "\n",
    "season_year_dict = {}\n",
    "\n",
    "for key, value in md_final.items():\n",
    "    # Check the title field\n",
    "    if 'title' in value:\n",
    "        match = re.search(r'\\b(Winter|Spring|Summer|Autumn|Fall)\\s+\\d{4}\\b', value['title'])\n",
    "        if match:\n",
    "            season_year_dict[key] = match.group(0)\n",
    "            continue  # Skip to the next item if found\n",
    "\n",
    "    # Check the Project Title field\n",
    "    if 'Project Title' in value:\n",
    "        match = re.search(r'\\b(Winter|Spring|Summer|Autumn|Fall)\\s+\\d{4}\\b', value['Project Title'])\n",
    "        if match:\n",
    "            season_year_dict[key] = match.group(0)\n",
    "            continue\n",
    "\n",
    "    season_year_dict[key] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49d7a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/intermediate/metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(md_final, f)\n",
    "\n",
    "with open('data/intermediate/term.pkl', 'wb') as f:\n",
    "    pickle.dump(season_year_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc85c1",
   "metadata": {},
   "source": [
    "### General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46fcb8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 19.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://stackoverflow.com/questions/71025130/how-to-extract-a-table-from-a-website-using-beautifulsoup\n",
    "stats = {}\n",
    "\n",
    "with open('course_pages.jsonl', 'r') as f:\n",
    "   for line in tqdm(f):\n",
    "       j = json.loads(line)\n",
    "       soup = BeautifulSoup(j['text'], 'html.parser')\n",
    "\n",
    "       tables = soup.find_all('table')\n",
    "\n",
    "       stats[j['url']] = [pd.read_html(StringIO(str(t))) for t in tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66630749",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/intermediate/stats.pkl', 'wb') as f:\n",
    "    pickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69c353",
   "metadata": {},
   "source": [
    "### Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:02,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "interest = {}\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "with open('raw_data/ocr_results.jsonl', 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        line = json.loads(line)\n",
    "\n",
    "        url = line['course_url']\n",
    "        image = line['questions']\n",
    "\n",
    "        if url not in interest:\n",
    "            interest[url] = {}\n",
    "        \n",
    "        for entry in image:\n",
    "            q = entry['question']\n",
    "            ocr_res = entry['ocr']\n",
    "\n",
    "            if 'responses' not in ocr_res:\n",
    "                continue\n",
    "\n",
    "            text = ocr_res['responses'][0]['textAnnotations'][0]['description']\n",
    "\n",
    "            \n",
    "            if 'Now that' in q:\n",
    "                pattern_prior = r'(Diminished|Satisfied|Heightened|Total)\\s*[((]\\s*(\\d+)\\s*[))]'\n",
    "                matches = re.findall(pattern_prior, text, re.IGNORECASE)\n",
    "                result = {label: int(value) for label, value in matches}\n",
    "                interest[url][q] = result\n",
    "\n",
    "                total = 0\n",
    "                for tag, count in result.items():\n",
    "                    if tag != 'Total':\n",
    "                        total += count\n",
    "                if result['Total'] != total:\n",
    "                    print(f\"Total mismatch for {url}: {result['Total']} != {total}\")\n",
    "\n",
    "            if 'Prior to' in q:\n",
    "                pattern = r'(Very High|Very Low|Neutral|High|Low|Total)\\s*\\((\\d+)\\)'\n",
    "                matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "                result = {label: int(value) for label, value in matches}\n",
    "                interest[url][q] = result\n",
    "\n",
    "                total = 0\n",
    "                for tag, count in result.items():\n",
    "                    if tag != 'Total':\n",
    "                        total += count\n",
    "                if result['Total'] != total:\n",
    "                    print(f\"Total mismatch for {url}: {result['Total']} != {total}\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dddb9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/intermediate/interest.pkl', 'wb') as f:\n",
    "    pickle.dump(interest, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8421c3",
   "metadata": {},
   "source": [
    "### Professor Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3b27598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_prof_q(stats):\n",
    "  dct = {}\n",
    "  for course, dfs in tqdm(stats.items()):\n",
    "    for df in dfs:\n",
    "      if isinstance(df[0], pd.DataFrame):\n",
    "        if df[0].columns[0] != 'Comments':\n",
    "          for q in df[0].iloc[:, 0].values:\n",
    "\n",
    "            if isinstance(q, str):\n",
    "              q = q.lower()\n",
    "              if q.startswith('overall, the instructor') or q.startswith('overall, this instructor'):\n",
    "                dct[course] = df[0]\n",
    "                break\n",
    "\n",
    "  return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48eacae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 2901.45it/s]\n"
     ]
    }
   ],
   "source": [
    "prof_q = select_prof_q(stats)\n",
    "\n",
    "prof_q_df = pd.concat(\n",
    "    [df.assign(source=key) for key, df in prof_q.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "prof_q_df.to_csv('data/intermediate/prof_q.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02263ea5",
   "metadata": {},
   "source": [
    "### Challenge of the Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee29d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_challenge_q(stats):\n",
    "  dct = {}\n",
    "  for course, dfs in tqdm(stats.items()):\n",
    "    for df in dfs:\n",
    "      if isinstance(df[0], pd.DataFrame):\n",
    "        if df[0].columns[0] != 'Comments':\n",
    "          for q in df[0].iloc[:, 0].values:\n",
    "\n",
    "            if isinstance(q, str):\n",
    "              q = q.lower()\n",
    "              if q.startswith('this course challenged me intellectually'):\n",
    "                dct[course] = df[0]\n",
    "                break\n",
    "\n",
    "  return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3bc2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 761.38it/s]\n"
     ]
    }
   ],
   "source": [
    "challenge_q = select_challenge_q(stats)\n",
    "\n",
    "challenge_q_df = pd.concat(\n",
    "    [df.assign(source=key) for key, df in challenge_q.items()],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "challenge_q_df.rename(columns={'Unnamed: 0': 'Question'}, inplace=True)\n",
    "challenge_q_df.to_csv('data/intermediate/challenge_q.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
